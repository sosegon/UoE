%% Template for MLP Coursework 2 / 6 November 2017 

%% Based on  LaTeX template for ICML 2017 - example_paper.tex at 
%%  https://2017.icml.cc/Conferences/2017/StyleAuthorInstructions

\documentclass{article}

\usepackage[T1]{fontenc}
\usepackage{amssymb,amsmath}
\usepackage{txfonts}
\usepackage{microtype}

% For figures
\usepackage{graphicx}
\usepackage{subfigure} 

% For citations
\usepackage{natbib}

% For algorithms
\usepackage{algorithm}
\usepackage{algorithmic}

% the hyperref package is used to produce hyperlinks in the
% resulting PDF.  If this breaks your system, please commend out the
% following usepackage line and replace \usepackage{mlp2017} with
% \usepackage[nohyperref]{mlp2017} below.
\usepackage{hyperref}
\usepackage{url}
\urlstyle{same}

% Packages hyperref and algorithmic misbehave sometimes.  We can fix
% this with the following command.
\newcommand{\theHalgorithm}{\arabic{algorithm}}


% Set up MLP coursework style (based on ICML style)
\usepackage{mlp2017}
\mlptitlerunning{Face classification applications (\studentNumber)}
\bibliographystyle{icml2017}


%% You probably do not need to change anything above this comment

%% REPLACE this with your student number
\def\studentNumber{s1700260}

\begin{document} 

\twocolumn[
\mlptitle{Face classification applications}

\centerline{\studentNumber}

\vskip 7mm
]

\begin{abstract} 
The face is perhaps the part of human body that carries the majority of information about a person. By analizing the different attributes of a face we can make infers about that person, e.g., gender, age, mood and more. In this review, I present a set of approaches used in computer vision to classify human faces and their applications. Moreover, I provide an analysis of the features used to perform the classification tasks along with their advantages and disadvantages. Finally,  I discuss about the variations of the approaches and further work.

\end{abstract} 

\section{Introduction}
Human classification is a common task performed in a multitude of scenarios. Its objective varies depending on the domain where it is performed, but in many cases it is meant to make infers about a person of a given class. The range of applications varies from entertainment to surveillance including health, sports and more. The classification can be performed as simply as using a single feature of a subject or using more complex systems that analyse the correlation between different sets of features. No matter the way a system classifies people, one of the key aspect of every system is the data it uses; face is a part of every people that provides a lot of information.

As mentioned, the human face is a source for vast information. Depending on the features to analyze and the way they are analyzed, a subject can be classified into one group or another. For this reason it is important to have a good understanding of the domain where the classification is going to be performed in order to get proper results. For instance, in a system that is meant to determine the mood of a person, it makes more sense to use the facial expressions rather than the hair or eye color.

For the common eye, it is easy to identify a set of features from almost any object (faces included). However, in computer vision this is a non-trivial task. Several general purpose feature detectors from images have been developed e.g. \citep{harris1988combined} and \citep{lowe1999object}, as well as domain specific ones: \citep{chow1993towards} and \citep{colmenarez1999detection}. No matter their domain, the ultimate goal of these approaches is to provide information in a meaningful way for a system, so this is able to perform a given task with good results. In classification, some alternatives are able to extract features and categorize faces at once \citep{fleming1990categorization}.

The information extracted from faces can be used to feed a variety of systems for different purposes. Many of the alternatives are based on machine learning methods, being neural networks a popular choice for tasks like face detection \citep{rowley1998neural}, face recognition, \citep{lawrence1997face} and face verification \citep{sun2013hybrid}; all of them intrinsicaly classification tasks.


\section{Face information}
Even though there are approaches that address the problem of feature detection and they have been proven to give good results, it is important to understand the information that we can get from the human face. This way it would be possible to get more insights about how some systems leverage the information from a face and how they can be improved or modified to perform other tasks. Here, I will focus in the geometry and color information provided by faces.

\subsection{Geometry}
Geometry-wise, there are two important characteristic in the human face. First, it is well structured, meaning that the positions of its different components have little variation from subject to subject; the mouth are located in the bottom, the eyes close to the top, and so on. Some applications take advantage of this property to synthesise data to train neural networks \citep{hu2016frankenstein}, copy a makeup style from one face to another \citep{guo2009digital}, or to simply replace faces in photographies for entertainment purposes \citep{bitouk2008face}. Moverover, the well defined structure of a face along with its enourmous differences to other elements make possible systems for face detection \citep{zhu2006fast}.

Related to the well structured composition of faces there is its horizontal symmetry. However this can be broken by hair styles.

In the other hand, the variability of the face components from subject to subject (shape, relative position, relative size, etc.) is high enough that it is possible to have approaches for face recognition \citep{ahonen2004face} which can be used in applications for authentication or reidentification. In addition, the components of a face in a single subject are not static, (their shapes can vary) which is clearly evident in facial expressions, an attribute that can be used to recognize moods or emotions \citep{adolphs2002recognizing}. This characteristic has been used in systems aimed to facilitate human computer interaction \citep{yacoob1996recognizing}.

Other than facial expressions, subjects can modify the geometry of their faces by using makeup, wearing accesories like glasses and earrings, or even by changing their hair style. This situation evidently increases the variability of a single face, which supposes a challenge for systems that rely in the geometry information of faces. Some alternatives have addressed this problem by performing the correlation between the raw face and the modified one \citep{guo2014face}. Other approaches have focused their efforts in the detection of such accessories \citep{jing2000glasses} and  \citep{wu2004glasses}

\subsection{Color}
In computer vision, one of the salient characteristics of color is the ability to be represented in a multitude of formats. Thanks to this property, it is possible to convert the color information in a picture from  the default color space (usually in the red, green and blue channels) to a more suitable format depending on the application domain. This is leveraged by a multitude of systems for different purposes including explicit image detection \citep{basilio2011explicit} and face detection \citep{garcia1999face}

The human skin color in digital images has been widely studied. One of the major developments thrown by previous researches in this area is the determination of the proper color space to study the human skin. Even though that a proper analysis of a color space can give good results for applications over human skin color \citep{albiol2001optimum}, YCbCr color space has demonstrated to give the best results. The main reason is that for skin detection, the majority of systems discard the luminance of the image (Y component) as stated in \citep{vezhnevets2003survey}

In the human face not only the skin provides color information, other components like the eyes and hair provide information in regards to that matter. The analysis of the color of these elements has proven to be useful in applications like gaze tracking \citep{kim1999vision} and person recognition and image indexing \citep{yacoob2006detection}.

Like geometry, face color can be prone to changes too. Here the changes can also depend on the behaviour of the subjects e.g. the use of makeup. However, most of the color variability in an image comes from the configuration of the device to capture the scene (exposure time, shutter speed, etc.), and the environment setup (lighting, shadows, etc.). Nonetheless, skin color variability not only brings problems, it can be leveraged to make health related analysis \citep{tsumura2003image}

\section{Classification applications with faces}

There is a wide range of applications that lay their foundations in the classification task using images with faces. Based on the geometry and color information mentioned ealier, I will describe and analysis three systems that uses that kind of data. The fist system uses geometry information represented as histogram of gradients (HOG) for face recognition \citep{deniz2011face}. The second system detect faces based on skin region detection using color tranformations \citep{hsu2002face}. Finally, the third systems uses both geometry and color information to determine the presence of makeup in faces \citep{chen2013automatic}.

\subsection{Face recognition using HOG}

As stated by \citep{deniz2011face} HOG is a technique founded over the number of edge orientations ocurrences within the local vecinity in an image. In their work, the authors propose a method based on the previous project by \citep{albiol2008face}. The main differences with the previous work lies in the way HOG is performed, a combination of classifiers, and the databases used to ran the experiments. The different way to perform HOG is aimed to reduce the possible dependency on the facial landmarks localization of previous results. A facial landmark is a salient feature within a face, in other words, an interest point.

There are two proposed ways to perform HOG in a face image. The first one lies in the location of the facial landmarks as well, however, the key point here is redundancy. Once the facial landmarks are localized, HOG is performed over each one of them at different patch sizes. That means that the bigger the patch size, the higher the redundancy of the retrieved information by HOG as seen in Figure 2 in \citep{deniz2011face}. In the second method, an image face is simply divided in non overlapped patches over which HOG is executed.

As mentioned by the authors, the redundancy of the first method may cause overfitting if the classifier does not have a mechanism for feature selection. On the other hand, the second alternative could prevent that situation due to its non overlapping nature. However, some amount of redundancy may be necessary to avoid the other undesired effect in machine learning models: underfitting. In fact, some HOG implementations can be configured to create a certain amount of redundancy by adding normalization over overlaped blocks of cells.

Another option that could help to increase the robutness of the feature descriptor is the combination of several types of features. Even though, the authors experimented combinations of HOG with Principal Component Analysis (PCA) and Latent Dirichlet Allocation (LDA), other methods like Local Binary Patterns may give good results. In fact, an alternative that combines HOG and LBP has proven to perform well in adverse situations like occlusion as seen in \citep{wang2009hog}.

The proposed method to make the recognition of a face is based in the idea of weak classifiers, something that has proven to be good in several scenarios including the very same face recognition task \citep{yang2004face}. Other machine learning method that can perform well in this kind of problems is neural networks as demonstrated in \citep{parkhi2015deep}. However, the success of a neural network is highly tied to a big amount of data for training process.

Finally, the datasets used to perform the experiments presented considerable differences from one to another. As seen in Figure 4 of their work, the variance of the facial landmarks is quite different from one database to the other. This is not a minor issue since the performance of the method varies according to the dataset used. There is no much that can be done here since each dataset has their own charactersistics, some of them were even built for a specific purpose.  However, the naive alternative is to combine all the databases to get a more robust classifier.

Even though the proposed method does not irrupt in the computer vision field, it was able to improve the results of its antecesor. The main point in this solution is the way of extract face features; it uses the same mechanism of the previous approach, but its execution is different. As seen in many scenarios, a proper definition of features can lead to expected results and verify the validity of an hypothesis, something that can was accomplished in this work. Futher work could be aimed to verify the performance of the feature extraction methodology in other tasks like face detection.

\subsection{Face detection in color images}
The approach for face detecttion proposed by \citep{hsu2002face} is highly focused in the analysis of color in images. The solution is motivated by the lack of previous color-based alternatives that are robust enough to detect skin colors in different light conditions and complex background. The proposed method relies in two main components. The first one is aimed to detect face candidates based on some color transformations performed in an image. The second element is focused in the validation of the face candidates by detecting facial features. 

The authors are aware of the challenges related to the definition of skin tones in color images due to the lighting conditions, and the previous work in the field. Based on this knowledge, the solution starts by compesating the lighting condition by using a reference white area, which allows to reduce the number of false positives. As demonstrated in other related works, YCbCr is the preferred color space when it comes to human skin detection. However, unlike other solutions where the skin pixels were detected by simply checking their values against a predefined range, the algorithm performs a non-linear transformation the helps to reduce the false positives as well.

Once the face candidate region is detected, it is analyzed to find facial features. This analysis relies in the distinctive chroma an luminance components of eyes and mouth. In summary, the solution creates an intensity map that highlights the regions where eyes and mouth are located. Such intensity map is created through a sequence of non linear transformation of the image components in the YCbCr color space. Once the three regions are detected, all the triangle zones are computed and filtered under a threshold to finally detect a face. 

As described, this solution makes an intense analysis of the color in an image. However, due to the lack of semantic analysis, some anthropomorphic areas can be detected as human faces e.g. toys. A further work could consider an analysis of the context in the image to reduce the false positives and improve results. Finally, since the approach analyzes the luminance in an image, it could be used to detect fake or mounting images.


\subsection{Automatic Facial Makeup Detection with Application in Face Recognition}
Face recognition is a well studied task, there are many geometry-based approaches that have been proved to provide good results under certain conditions. However, in the real world there are many variables that can reduce the performance of such solutions. Makeup is one of those variables that challenges face recognition. The work proposed by \citep{chen2013automatic} is founded over the lack of previous solutions that address the problem of makeup and given that using it is a common habit among a great percentage of the population.

In their work, they propose a method that combines a set of color, geometric and texture features aimed to detect the presence of makeup in a face. Moreover, the solution is extended to be used in face recognition. As stated in their work, the use of makeup changes the perceptual appareance of people by highlighting characteristics and reducing flaws. This has been proved to have a huge impact in the performance of some recognition systems. For this reason, it is neccesary to redefine the set of features used to feed those solutions.

The main contribution of this work is the redefinition of the face features in order to consider the changes in shape, color and texture due to the use of makeup. The main objective is to provide a set of descriptorts that clearly determine the presence or absence of makeup, so a face recognition system can be tuned properly to maintain its performance under such conditions.

Unlike other works that make use of the YCbCr color space when it comes to human skin, here they use the HSV color space (Hue, Saturation, Value) that highlights makeup regions in the saturation channel. The solution proposes a definition of color descriptors by combining the local and global features. This is a good idea since it adds some redundancy but keeps fidelity over all images. Shape and texture descriptors are simpler but they still contribute to increase the robustness of the feature vector.

Their experiments proved to give good results, however since the work was highly focused in mid-age female image samples, further work could address a more general solution including other segments of the population. Moreover, since the solution used almost perfectly front face images, further work can also include profile pictures.

\section{Conclusions and further work}
As seen, the human face is a source of vast information and there are several classification applications that rely in that data. One of the key aspects of these applications is the way they define a face in terms of its features. Depending in the domain of the application some features are more useful than others. But the solutions go beyond that; it is not about the kind of information used to address a problem, the way it is processed and presented is very relevant in the success of an approach.

In addition, it is clearly evident that a given task can be addressed in different ways. Nonetheless, another important component of every approach is its foundation in previous work, this way new solutions can go beyond what have been proposed previously. In the case of applications with human faces, there is a lot of work done in regards to analyse their information and make use of them. However, the development does not seem to stop and every time new alternatives are proposed. Further reviews could be aimed to investigate what kind of information from human faces could be retrieved from sources other than 2D images, including Laser Imaging Detection and Ranging (LIDAR) and medical imagery, and the applications that can be done out of that.


\label{sec:concl}

\bibliography{example-refs}

\end{document} 


% This document was modified from the file originally made available by
% Pat Langley and Andrea Danyluk for ICML-2K. This version was
% created by Lise Getoor and Tobias Scheffer, it was slightly modified  
% from the 2010 version by Thorsten Joachims & Johannes Fuernkranz, 
% slightly modified from the 2009 version by Kiri Wagstaff and 
% Sam Roweis's 2008 version, which is slightly modified from 
% Prasad Tadepalli's 2007 version which is a lightly 
% changed version of the previous year's version by Andrew Moore, 
% which was in turn edited from those of Kristian Kersting and 
% Codrina Lauth. Alex Smola contributed to the algorithmic style files.  
